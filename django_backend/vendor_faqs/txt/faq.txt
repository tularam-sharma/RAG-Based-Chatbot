import os

import chromadb
from chromadb.utils import embedding_functions
from groq import Groq
import pandas
from dotenv import load_dotenv

load_dotenv()


ef = embedding_functions.SentenceTransformerEmbeddingFunction(
            model_name='sentence-transformers/all-MiniLM-L6-v2'
        )

chroma_client = chromadb.Client()
groq_client = Groq()


def _collection_name_for_vendor(vendor_id: str) -> str:
    safe_id = str(vendor_id).replace(' ', '_')
    return f"faqs_vendor_{safe_id}"


def ingest_faq_data(path, vendor_id: str):
    """Ingest CSV at `path` into a vendor-scoped Chroma collection.
    path may be a Path or string. """
    collection_name = _collection_name_for_vendor(vendor_id)
    if collection_name not in [c.name for c in chroma_client.list_collections()]:
        print(f"Ingesting FAQ data into Chromadb collection: {collection_name}...")
        collection = chroma_client.create_collection(
            name=collection_name,
            embedding_function=ef
        )
        df = pandas.read_csv(str(path))
        # basic schema validation
        if 'question' not in df.columns or 'answer' not in df.columns:
            raise ValueError("CSV must contain 'question' and 'answer' columns")
        docs = df['question'].to_list()
        metadata = [{'answer': ans} for ans in df['answer'].to_list()]
        ids = [f"{vendor_id}_id_{i}" for i in range(len(docs))]
        collection.add(
            documents=docs,
            metadatas=metadata,
            ids=ids
        )
        print(f"FAQ Data successfully ingested into Chroma collection: {collection_name}")
    else:
        print(f"Collection: {collection_name} already exists")


def get_relevant_qa(query, vendor_id: str):
    collection_name = _collection_name_for_vendor(vendor_id)
    
    # Check if collection exists
    existing_collections = [c.name for c in chroma_client.list_collections()]
    if collection_name not in existing_collections:
        raise ValueError(f"No FAQ data found for vendor {vendor_id}. Please upload a CSV file first.")
    
    collection = chroma_client.get_collection(
        name=collection_name,
        embedding_function=ef
    )
    result = collection.query(
        query_texts=[query],
        n_results=2
    )
    return result


def generate_answer(query, context):
    prompt = f'''Given the following context and question, generate answer based on this context only.
    If the answer is not found in the context, kindly state "I don't know". Don't try to make up an answer.
    
    CONTEXT: {context}
    
    QUESTION: {query}
    '''
    completion = groq_client.chat.completions.create(
        model=os.environ['GROQ_MODEL'],
        messages=[
            {
                'role': 'user',
                'content': prompt
            }
        ]
    )
    return completion.choices[0].message.content


def faq_chain(query, vendor_id: str):
    result = get_relevant_qa(query, vendor_id)
    try:
        result = get_relevant_qa(query, vendor_id)
    except Exception as e:
        # If no collection or other retrieval error, fallback to LLM
        llm_resp = llm_chain(query, vendor_id)
        return llm_resp + "\n-This response is generated by LLM as the requested data was not available in your uploaded Excel file"

    metadatas = result.get('metadatas', [])
    if not metadatas or not metadatas[0]:
        llm_resp = llm_chain(query, vendor_id)
        return llm_resp + "\n-This response is generated by LLM as the requested data was not available in your uploaded Excel file"

    context = "".join([r.get('answer', '') for r in metadatas[0]])
    if not context.strip():
        llm_resp = llm_chain(query, vendor_id)
        return llm_resp + "\n-This response is generated by LLM as the requested data was not available in your uploaded Excel file"

    print("Context:", context)
    answer = generate_answer(query, context)
    return answer


if __name__ == '__main__':
    print("Vendor-aware FAQ module. Use ingest_faq_data(path, vendor_id) to load vendor data.")