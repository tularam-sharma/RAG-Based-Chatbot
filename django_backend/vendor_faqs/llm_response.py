from groq import Groq
import os
import re
import pandas as pd
from pathlib import Path
from dotenv import load_dotenv
from pandas import DataFrame

load_dotenv()

GROQ_MODEL = os.getenv('GROQ_MODEL')

db_path = Path(__file__).parent / "db.sqlite"

client_sql = Groq()


comprehension_prompt = """You are an expert in understanding the context of the question and replying based on  the question provided. You will be provided with Question:  Do not write anything like 'Based on the data' or any other technical words. Just deny with a polite message if the data is not available in the uploaded Excel file.
Always add this to every response "\n-This response is generated by LLM as the requested data was not available in your uploaded Excel file"

"""


def generate_response(question):
    chat_completion = client_sql.chat.completions.create(
        messages=[
            {
                "role": "system",
                "content": comprehension_prompt,
            },
            {
                "role": "user",
                "content": question,
            }
        ],
        model=os.environ['GROQ_MODEL'],
        temperature=0.2,
        max_tokens=1024
    )

    return chat_completion.choices[0].message.content



def data_comprehension(question):
    chat_completion = client_sql.chat.completions.create(
        messages=[
            {
                "role": "system",
                "content": comprehension_prompt,
            },
            {
                "role": "user",
                "content": f"QUESTION: {question}. ",
            }
        ],
        model=os.environ['GROQ_MODEL'],
        temperature=0.2,
        # max_tokens=1024
    )

    return chat_completion.choices[0].message.content



def llm_chain(question, vendor_id=None):
    """Vendor-aware LLM chain. `vendor_id` is optional and currently unused,
    but accepted for future vendor-scoped prompts or data access.
    """
    sql_query = generate_response(question)

    answer = data_comprehension(question)
    return answer


if __name__ == "__main__":
    # question = "All shoes with rating higher than 4.5 and total number of reviews greater than 500"
    # sql_query = generate_sql_query(question)
    # print(sql_query)
    question = "Show top 3 shoes in descending order of rating"
    # question = "Show me 3 running shoes for woman"
    # question = "sfsdfsddsfsf"
    answer = llm_chain(question)
    print(answer)
